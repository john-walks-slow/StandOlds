---
title: "【人機爭霸】AlphaGo 再勝一仗　連續兩局擊敗李世乭"
author: "立場報道"
date: "2016-03-10T16:27:00"
categories:
  - "科技"
tags:
  - "圍棋"
image: "http://web.archive.org/web/2021im_/https://assets.thestandnews.com/media/photos/google-20-01_v8Zfn.png"
original_url: "thestandnews.com/technology/人機爭霸-alphago-再勝一仗-連續兩局擊敗李世乭"
---
![](http://web.archive.org/web/2021im_/https://assets.thestandnews.com/media/photos/google-20-01_v8Zfn.png)
> youtube 片段截圖

棋王爭勝戰，李世乭再次不敵由 Google DeepMind 研發的人工智能 AlphaGo。 AlphaGo 至今已連勝兩局。

在南韓首爾的比賽吸引了超過 86,000 人觀看，歷時 4 個半小時後，李世乭再次敗給人工智能。在今場比賽中，李世乭比 Alpha 更早用完原來分配的時間。

現年 39 歲的 DeepMind 創辦人 Demis Hassabis 難掩興奮感覺，在 Twitter 寫到：

> [#AlphaGo](http://web.archive.org/web/20211229061350/https://twitter.com/hashtag/AlphaGo?src=hash) wins match 2, to take a 2-0 lead!! Hard for us to believe. AlphaGo played some beautiful creative moves in this game. Mega-tense...
> 
> — Demis Hassabis (@demishassabis) [March 10, 2016](http://web.archive.org/web/20211229061350/https://twitter.com/demishassabis/status/707845224731508736)

AlphaGo 再次勝出的關鍵，就是機器學習 (Machine Learning)。

機器學習與傳統電腦程式編程不同：一般電腦程式要處理問題，就要依賴原來的程式編碼員寫下的一系列程式應付。比如程式若要用作計算加數，就只會容許用戶填下兩個不同數值計算，亦只能處理簡單加減問題。機器學習就剛好相反，程式本身被設計成可以自行學習處理問題的方法。現時一般會在機器學習用到的方法，是嘗試模仿人類神經系統的運作，科學家將之稱為「人工神經系統」。在人類神經系統，每個神經元都懂得與另一個神經元溝通，將傳遞和處理資訊。

同樣地，人工神經系統都會將自己處理到的資訊，逐層地交往更「高級」的人工神經元處理。最初這種技術只有 3 層人工神經系統，但近年開始開發到更多層，也就是可以處理的問題變得更加複雜。科學家將這種機器學習命名為：深層學習 （Deep Learning，也是 DeepMind 名字的由來）。最底層的「人工神經元」只會處理少量資訊，其後慢慢逐層累積更越來越多資訊，再由最「高層」的神經元將收集到的訊息組合為有意義的結果（例如：認出圍棋的步法，「思考」然後決定下一步棋）。簡單而言，深層學習就將極複雜的問題抽絲剝繭了解。不過電腦在學習過程中，則仍然會遇上很多問題，例如會「忘記」剛見到的事物等。

AlphaGo 今日再次得勝，絕不代表是人類的末日；相反，結果反映人類的成功，可以從古代只懂運用石器，經歷多年學習後，可以在機器中建構出智能。AlphaGo 要走到今天，連贏兩局，其實殊不簡單。

重溫比賽：

文／eh