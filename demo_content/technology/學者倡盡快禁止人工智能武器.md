---
title: "學者倡盡快禁止人工智能武器"
author: "立場報道"
date: "2017-11-14T16:03:00"
categories:
  - "科技"
tags:
  - "人工智能"
original_url: "thestandnews.com/technology/學者倡盡快禁止人工智能武器"
---
試想像無人機可被改裝為無孔不入、殺死目標人物於無聲無形的致命武器——人類只需輸入目標特徵，過程中完全無須人類參與。武器或能減少不必要的傷亡，可遙距取下恐怖分子的性命。然而，一旦武器落入心懷不軌的人手中，又會有甚麼結果？

倡議人士與科學家合作製作了一段有關人工智能武器的短片，呈現這個聽起來荒旦科幻，卻絕有可能發生的未來世界。片段將由加州大學人工智能教授 Stuart Russell 在聯合國武器會議中放映。電影中，無人機武器誤入他人手中，用作追殺政客。其後大學生也竟然成為目標，全部被無人機屠殺。 

Stuart Russell 指出：「短片中展示的只是現今科技能做到的情景，並非科幻故事。事實上，發展此類技術比自動駕駛車輛更容易，因為後者有更嚴格的安全標準。」他和影片製作成員強調，各國必須盡快訂立國際條文，禁止研發和製造包括武裝無人機、配備人工智能的坦克和自動武器等人工智能武器，以防止其成為新一代大殺傷力武器。

現時軍方是不同人工智能科技的最大贊助者，因為此類科技可幫助飛行器導航和執行偵測任務，加上成本比其他武器和士兵低，所以未來技術更可能有機會直接參與行動，殺死目標。有批評認為單是將生殺之權由機器處理，已經超越道德界線。另外，此類武器更可能被獨裁國家、恐怖主義者用作控制人口或打壓異己的殺人工具。

早前 Telsa 創辦人 Elon Musk 、 Deep Mind 人工智能部門創辦人 Mustafa Suleyman 連同超過 100 位人工智能專家發表聯署公開信，警告要訂立禁令，防止「第三次軍事變革」。在 2015 年，物理學家霍金亦與過千科學家聯署警告人工智能武器的禍害。現時已有 19 個國家禁止研發人工智能武器，包括阿根廷、巴基斯坦和埃及等國家。

來源：  
The Guardian, [Ban on killing robots urgently needed, say scientists](http://web.archive.org/web/20211229093006/https://www.theguardian.com/science/2017/nov/13/ban-on-killer-robots-urgently-needed-say-scientists),13 November 2017

文／Edward Ho 、審核／Alan Chiu