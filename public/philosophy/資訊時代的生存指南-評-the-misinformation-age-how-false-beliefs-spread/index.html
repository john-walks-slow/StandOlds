<!DOCTYPE html>
<html lang="en" data-theme="light">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  
  <title>
    
    資訊時代的生存指南：評《The Misinformation Age: How False Beliefs Spread》 | 立場舊聞
    
  </title>
  <meta name="viewport" content="width=device-width,minimum-scale=1">
  <meta name="description" content="中世紀的歐洲流傳著一則奇聞：在韃靼利亞（現今中亞至東北亞地區）有一種神秘的植物，結出的果實是一頭活生生的羔羊。由於臍帶和植物的莖相連結，這種植物羊無法自由覓食，只能在可及範圍內啃食植被。等到周圍的食物被消耗殆盡以後，這株植物便會和羊一同死去。植物羊的肉風味絕佳，血液甜如蜜，嚐過的人都難以忘懷。當時的探險家、貴族和學者們普遍相信韃靼植物羊的存在，少數抱持懷疑的人也因為不斷接觸到這樣的傳言，而逐漸相信確有其事。直到十七世紀中葉，才有瑞典學者前往東方進行系統性的調查，證明了植物羊只是人們捏造的生物。
我們或許會將植物羊傳說的廣泛流傳歸因於古代人的蒙昧無知。如果他們能夠接受現代科學的薰陶，便不至於會相信如此荒謬的傳聞。然而，事實並非如此。在距離中世紀數百年的現在，每天都有大量的消息飛快地散播，其中比植物羊更加荒誕不經的比比皆是。 2013 年美國 Public Policy Polling 的調查顯示，約有一千兩百萬美國人相信有外星來的蜥蜴人喬裝成人類，掌控著極大的統治權力，伊麗莎白女王、柯林頓夫婦、小布希等政治菁英都是牠們的同類； 2016 年的披薩門 (pizzagate) 事件中，將近一成的共和黨員堅信希拉蕊 · 柯林頓涉及販運雛妓，最後導致一名男子持槍襲擊被視為販運據點的披薩店。暫且不論這些統計數字是否準確，我們可以知道的是：許多人受過現代教育，卻仍然對這些錯謬的資訊深信不疑。
為什麼人們會相信並散佈虛假的資訊？這個問題正是 The Misinformation Age: How False Beliefs Spread (Yale University Press, 2018) 一書的核心。兩位作者，加州大學爾灣分校邏輯與科學哲學系的 Cailin O&rsquo;Connor 和 Owen Weatherall，在此書中應用網絡知識論 (network epistemology) 分析資訊在科學社群中傳遞的方式，解釋錯謬的資訊如何逐漸擴散，並基於他們的研究結果反思現行的社會體制。本文試圖對此書做一個簡單的摘要，並就其內容做出延伸思考。
在當代社會中，科學家們對資訊的處理通常最為嚴謹。如果科學家在相互傳遞資訊的時候仍會犯下某些錯誤，那其他的群體中就也很有可能出現類似的現象。作者們基於這樣的觀察，擬定了本書的基本架構：他們首先界定資訊的真偽，提出一個以實用性為依歸的真理標準，再對科學社群內的資訊傳遞機制進行完整的考察，指出其中可能出現的問題。在這個工作完成以後，他們進一步檢視各種影響科學研究的外部因素，說明不具備科學專業的人如何能夠操縱大眾對科學研究的看法。最後將關注的場域由科學社群拓展到一般社群，解釋假資訊如何在普羅大眾之間散播。
極化與從眾
科學社群中可能出現的現象之一是立場的極化 (polarization) 。意見相左的兩個群體會因為各種原因而逐漸加深歧見，最後分別佔據光譜的兩個極端。假使有一名科學家企圖判定對立的兩個科學理論 A 和 B 孰真孰假，除了自己作實驗以外，另一個常見的做法是要求身邊的同儕提供研究的成果，藉以蒐集更多關於這兩個理論的資訊。如果他的同儕們恰好都是 A 理論的支持者，他們會傾向提供較為支持 A 理論的證據，進而大大地提高這位科學家接受 A 理論的機會。如果他因此斷定 A 理論是真的，進而認為所有接受 B 理論的人都在研究能力上出了問題，拒絕和他們交換資訊，就會出現意見極化的現象。接受不同科學理論的人互相將對方當作三流的科學家，形成了兩個不互相交流的封閉群體。兩個群體之中的科學家都無法接觸到另一邊的資訊，從而無法基於完整而全面的證據評價兩個理論的優劣。
一個與極化相似的現象是從眾 (conformity) 。科學家在研究特定議題的時候，時常會接觸到旁人的想法，並以此作為證據，推論出與這些人相同的結果。作者們用了一個簡單的案例來說明這個現象：假使有五十個人在考慮購入日產或通用汽車的股票，其中每一個人都各自有些不能與他人分享的小道消息。兩個人手上的消息顯示通用汽車的股票會表現得比較好；其他四十八人手上的消息恰好相反，支持購買日產的股票。假使頭兩個人買了通用汽車的股票，並且讓剩下的人看到自己做出了這樣的選擇，第三個人在做決定的時候可能會想：既然前面兩個人都買了通用，那我手頭上有的資訊或許是錯誤的。秉持這樣的想法，這個人也會傾向於買進通用汽車的股票。接下來的每一個人可能都會按照相同的思路，買進通用的股票。這樣的思路將會導致一個奇怪的結果：絕大多數人擁有的資訊都支持購買日產的股票，最後卻都做出了和自己資訊不相符的決定。和極化一樣，從眾的傾向也容易讓科學家形成一個意見單一的群體，而忽略了支持不同理論的證據。
這兩個現象恰好是對稱的：如果我們將他人的不同意見棄若敝屣，就會產生意見極化的風險；如果我們過於重視與自己立場相近的意見，就可能犯下從眾的缺失。它們導致相同的結果，使得科學家們無法平衡地評估各方的資訊。對熟悉心理學的讀者來說，這兩個現象大概是已經聽過千百遍的陳腔濫調。極化和從眾分別是確認偏誤 (confirmation bias) 和從眾偏誤 (conformity bias) 的結果，這兩種認知偏誤多年來已經被深入地討論和研究，為什麼哲學家還要大費周章地解釋這樣的老生常談？這個問題恰好揭示了本書的一個重點：就算每一個個體都高度理性，還是有可能散播錯誤的資訊。
作者們以經濟學中的 Bala-Goyal 模型模擬了科學社群內的資訊傳遞機制，這個模型只包含幾個點，以及將某些點相連的線段。每一個點代表一個科學家，兩點如果有線段連結，代表這兩個科學家會交換各自的研究成果。每一個點上有特定的數值，代表他們相信特定理論的程度。在每一個階段，科學家們參照他們從身邊同儕獲取的資訊，以貝葉斯定理 (Bayes&#39; theorem) 修正自己對該理論的看法。從這樣一個高度抽象、不涉及任何認知偏誤的模型中，作者們仍然能夠推導出極化和從眾這兩個現象。這告訴我們：就算科學家在蒐集資訊的過程中保持著全然理性、不受偏誤左右的態度，只要他和同儕相互交換意見，並且依照所得到的證據修正對他人的看法，上述的兩個現象就很可能會出現。在這種理想的資訊交換過程中尚且如此，現實社會中的意見極化只可能會更加嚴重。">
  <meta name="generator" content="Hugo 0.92.0" />
  <meta name="robots" content="index, follow">
  <link rel="stylesheet" href="/css/bundle.min.8974faa57fedc134769cd508a1b6f7e5d39cbe42bc2df9b5ca66b9f0fd9cf7ab.css" crossorigin="anonymous" integrity="sha256-iXT6pX/twTR2nNUIobb35dOcvkK8Lfm1yma58P2c96s=">

  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">
  
  <link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#00aba9">
  
  <link rel="shortcut icon" href="/favicon/favicon.ico">
  <meta name="msapplication-TileColor" content="#00aba9">
  <meta name="msapplication-config" content="/favicon/browserconfig.xml">
  <meta name="theme-color" content="#00aba9">
  <meta name="og:title" content="資訊時代的生存指南：評《The Misinformation Age: How False Beliefs Spread》">
  <meta name="og:description" content="中世紀的歐洲流傳著一則奇聞：在韃靼利亞（現今中亞至東北亞地區）有一種神秘的植物，結出的果實是一頭活生生的羔羊。由於臍帶和植物的莖相連結，這種植物羊無法自由覓食，只能在可及範圍內啃食植被。等到周圍的食物被消耗殆盡以後，這株植物便會和羊一同死去。植物羊的肉風味絕佳，血液甜如蜜，嚐過的人都難以忘懷。當時的探險家、貴族和學者們普遍相信韃靼植物羊的存在，少數抱持懷疑的人也因為不斷接觸到這樣的傳言，而逐漸相信確有其事。直到十七世紀中葉，才有瑞典學者前往東方進行系統性的調查，證明了植物羊只是人們捏造的生物。
我們或許會將植物羊傳說的廣泛流傳歸因於古代人的蒙昧無知。如果他們能夠接受現代科學的薰陶，便不至於會相信如此荒謬的傳聞。然而，事實並非如此。在距離中世紀數百年的現在，每天都有大量的消息飛快地散播，其中比植物羊更加荒誕不經的比比皆是。 2013 年美國 Public Policy Polling 的調查顯示，約有一千兩百萬美國人相信有外星來的蜥蜴人喬裝成人類，掌控著極大的統治權力，伊麗莎白女王、柯林頓夫婦、小布希等政治菁英都是牠們的同類； 2016 年的披薩門 (pizzagate) 事件中，將近一成的共和黨員堅信希拉蕊 · 柯林頓涉及販運雛妓，最後導致一名男子持槍襲擊被視為販運據點的披薩店。暫且不論這些統計數字是否準確，我們可以知道的是：許多人受過現代教育，卻仍然對這些錯謬的資訊深信不疑。
為什麼人們會相信並散佈虛假的資訊？這個問題正是 The Misinformation Age: How False Beliefs Spread (Yale University Press, 2018) 一書的核心。兩位作者，加州大學爾灣分校邏輯與科學哲學系的 Cailin O&rsquo;Connor 和 Owen Weatherall，在此書中應用網絡知識論 (network epistemology) 分析資訊在科學社群中傳遞的方式，解釋錯謬的資訊如何逐漸擴散，並基於他們的研究結果反思現行的社會體制。本文試圖對此書做一個簡單的摘要，並就其內容做出延伸思考。
在當代社會中，科學家們對資訊的處理通常最為嚴謹。如果科學家在相互傳遞資訊的時候仍會犯下某些錯誤，那其他的群體中就也很有可能出現類似的現象。作者們基於這樣的觀察，擬定了本書的基本架構：他們首先界定資訊的真偽，提出一個以實用性為依歸的真理標準，再對科學社群內的資訊傳遞機制進行完整的考察，指出其中可能出現的問題。在這個工作完成以後，他們進一步檢視各種影響科學研究的外部因素，說明不具備科學專業的人如何能夠操縱大眾對科學研究的看法。最後將關注的場域由科學社群拓展到一般社群，解釋假資訊如何在普羅大眾之間散播。
極化與從眾
科學社群中可能出現的現象之一是立場的極化 (polarization) 。意見相左的兩個群體會因為各種原因而逐漸加深歧見，最後分別佔據光譜的兩個極端。假使有一名科學家企圖判定對立的兩個科學理論 A 和 B 孰真孰假，除了自己作實驗以外，另一個常見的做法是要求身邊的同儕提供研究的成果，藉以蒐集更多關於這兩個理論的資訊。如果他的同儕們恰好都是 A 理論的支持者，他們會傾向提供較為支持 A 理論的證據，進而大大地提高這位科學家接受 A 理論的機會。如果他因此斷定 A 理論是真的，進而認為所有接受 B 理論的人都在研究能力上出了問題，拒絕和他們交換資訊，就會出現意見極化的現象。接受不同科學理論的人互相將對方當作三流的科學家，形成了兩個不互相交流的封閉群體。兩個群體之中的科學家都無法接觸到另一邊的資訊，從而無法基於完整而全面的證據評價兩個理論的優劣。
一個與極化相似的現象是從眾 (conformity) 。科學家在研究特定議題的時候，時常會接觸到旁人的想法，並以此作為證據，推論出與這些人相同的結果。作者們用了一個簡單的案例來說明這個現象：假使有五十個人在考慮購入日產或通用汽車的股票，其中每一個人都各自有些不能與他人分享的小道消息。兩個人手上的消息顯示通用汽車的股票會表現得比較好；其他四十八人手上的消息恰好相反，支持購買日產的股票。假使頭兩個人買了通用汽車的股票，並且讓剩下的人看到自己做出了這樣的選擇，第三個人在做決定的時候可能會想：既然前面兩個人都買了通用，那我手頭上有的資訊或許是錯誤的。秉持這樣的想法，這個人也會傾向於買進通用汽車的股票。接下來的每一個人可能都會按照相同的思路，買進通用的股票。這樣的思路將會導致一個奇怪的結果：絕大多數人擁有的資訊都支持購買日產的股票，最後卻都做出了和自己資訊不相符的決定。和極化一樣，從眾的傾向也容易讓科學家形成一個意見單一的群體，而忽略了支持不同理論的證據。
這兩個現象恰好是對稱的：如果我們將他人的不同意見棄若敝屣，就會產生意見極化的風險；如果我們過於重視與自己立場相近的意見，就可能犯下從眾的缺失。它們導致相同的結果，使得科學家們無法平衡地評估各方的資訊。對熟悉心理學的讀者來說，這兩個現象大概是已經聽過千百遍的陳腔濫調。極化和從眾分別是確認偏誤 (confirmation bias) 和從眾偏誤 (conformity bias) 的結果，這兩種認知偏誤多年來已經被深入地討論和研究，為什麼哲學家還要大費周章地解釋這樣的老生常談？這個問題恰好揭示了本書的一個重點：就算每一個個體都高度理性，還是有可能散播錯誤的資訊。
作者們以經濟學中的 Bala-Goyal 模型模擬了科學社群內的資訊傳遞機制，這個模型只包含幾個點，以及將某些點相連的線段。每一個點代表一個科學家，兩點如果有線段連結，代表這兩個科學家會交換各自的研究成果。每一個點上有特定的數值，代表他們相信特定理論的程度。在每一個階段，科學家們參照他們從身邊同儕獲取的資訊，以貝葉斯定理 (Bayes&#39; theorem) 修正自己對該理論的看法。從這樣一個高度抽象、不涉及任何認知偏誤的模型中，作者們仍然能夠推導出極化和從眾這兩個現象。這告訴我們：就算科學家在蒐集資訊的過程中保持著全然理性、不受偏誤左右的態度，只要他和同儕相互交換意見，並且依照所得到的證據修正對他人的看法，上述的兩個現象就很可能會出現。在這種理想的資訊交換過程中尚且如此，現實社會中的意見極化只可能會更加嚴重。">
  <meta name="og:type" content="article">
  <meta name="og:site_name" content="立場舊聞">
  <meta name="og:url" content="/philosophy/%E8%B3%87%E8%A8%8A%E6%99%82%E4%BB%A3%E7%9A%84%E7%94%9F%E5%AD%98%E6%8C%87%E5%8D%97-%E8%A9%95-the-misinformation-age-how-false-beliefs-spread/">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="og:image" content="">
  <meta name="twitter:image" content="">
  
  
  
  
</head>

<body>

  <script type="text/javascript">
    
    function detectTheme() {
      var theme = "light";

      if (window.matchMedia("(prefers-color-scheme: dark)").matches) {
        var theme = "dark";
      }

      if (localStorage.getItem("theme")) {
        var theme = localStorage.getItem("theme");
      }

      if (theme == "dark") {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    }

    detectTheme();
  </script>
  
  <header id="site-header" class="l-compact">
  <nav class="l-container_site">
    <div class="branding">
        <h1 class="branding-title">
          <a href="/" accesskey="h" title="Home (Alt + H)">StandOlds</a>
        </h1>
      <p class="branding-tagline">立場新聞 2015~2021 精選</p>
    </div>
    
    <div id="site-nav">
      <label class="toggle" accesskey="n" title="Open Site Navigation (Alt + N)">
        <input id="nav-toggle" type="checkbox"></input>
        <span class="nav-button"></span>
      </label>
      <ul class="menu">
        <li class="menu-item">
          <a href="/topics/">專題</a>
        </li>
        <li class="menu-item">
          <a href="/categories/">分類</a>
        </li>
        <li class="menu-item">
          <a href="/about/">關於</a>
        </li>
      </ul>
    </div>
  </nav>
  <progress id="reading-progress" max="100" value="0" ></progress>
</header>

  

  <main id="site-main" role="main">
    
<article class="l-container_content card">
  <header class="card-header">
  
  <div class="card-meta">
    
  
    <span><time datetime="2019-09-09 07:05:00 &#43;0000 UTC">Sep 9 2019</time> · 12 min read</span>
    <ul class="taxonomy-list_categories">
      <li><a href="/categories/%E5%93%B2%E5%AD%B8/" class="taxonomy-item">哲學</a></li>
    </ul>
  </div>
  <h1 class="card-title"><a href="/philosophy/%E8%B3%87%E8%A8%8A%E6%99%82%E4%BB%A3%E7%9A%84%E7%94%9F%E5%AD%98%E6%8C%87%E5%8D%97-%E8%A9%95-the-misinformation-age-how-false-beliefs-spread/">資訊時代的生存指南：評《The Misinformation Age: How False Beliefs Spread》</a></h1>
  

  

</header>

  <section class="card-content">
    <p>

<figure>
    <a href="http://web.archive.org/web/2020im_/https://assets.thestandnews.com/media/photos/hear-04_8i7JD.png" target="calligraphy-image">
      <img loading="lazy" src="http://web.archive.org/web/2020im_/https://assets.thestandnews.com/media/photos/hear-04_8i7JD.png" alt="A Decorative Image">
    </a>
  
</figure>
</p>
<p>中世紀的歐洲流傳著一則奇聞：在韃靼利亞（現今中亞至東北亞地區）有一種神秘的植物，結出的果實是一頭活生生的羔羊。由於臍帶和植物的莖相連結，這種植物羊無法自由覓食，只能在可及範圍內啃食植被。等到周圍的食物被消耗殆盡以後，這株植物便會和羊一同死去。植物羊的肉風味絕佳，血液甜如蜜，嚐過的人都難以忘懷。當時的探險家、貴族和學者們普遍相信韃靼植物羊的存在，少數抱持懷疑的人也因為不斷接觸到這樣的傳言，而逐漸相信確有其事。直到十七世紀中葉，才有瑞典學者前往東方進行系統性的調查，證明了植物羊只是人們捏造的生物。</p>
<p>我們或許會將植物羊傳說的廣泛流傳歸因於古代人的蒙昧無知。如果他們能夠接受現代科學的薰陶，便不至於會相信如此荒謬的傳聞。然而，事實並非如此。在距離中世紀數百年的現在，每天都有大量的消息飛快地散播，其中比植物羊更加荒誕不經的比比皆是。 2013 年美國 Public Policy Polling 的調查顯示，約有一千兩百萬美國人相信有外星來的蜥蜴人喬裝成人類，掌控著極大的統治權力，伊麗莎白女王、柯林頓夫婦、小布希等政治菁英都是牠們的同類； 2016 年的披薩門 (pizzagate) 事件中，將近一成的共和黨員堅信希拉蕊 · 柯林頓涉及販運雛妓，最後導致一名男子持槍襲擊被視為販運據點的披薩店。暫且不論這些統計數字是否準確，我們可以知道的是：許多人受過現代教育，卻仍然對這些錯謬的資訊深信不疑。</p>
<p>為什麼人們會相信並散佈虛假的資訊？這個問題正是 <em>The Misinformation Age: How False Beliefs Spread</em> (Yale University Press, 2018) 一書的核心。兩位作者，加州大學爾灣分校邏輯與科學哲學系的 Cailin O&rsquo;Connor 和 Owen Weatherall，在此書中應用網絡知識論 (network epistemology) 分析資訊在科學社群中傳遞的方式，解釋錯謬的資訊如何逐漸擴散，並基於他們的研究結果反思現行的社會體制。本文試圖對此書做一個簡單的摘要，並就其內容做出延伸思考。</p>
<p>在當代社會中，科學家們對資訊的處理通常最為嚴謹。如果科學家在相互傳遞資訊的時候仍會犯下某些錯誤，那其他的群體中就也很有可能出現類似的現象。作者們基於這樣的觀察，擬定了本書的基本架構：他們首先界定資訊的真偽，提出一個以實用性為依歸的真理標準，再對科學社群內的資訊傳遞機制進行完整的考察，指出其中可能出現的問題。在這個工作完成以後，他們進一步檢視各種影響科學研究的外部因素，說明不具備科學專業的人如何能夠操縱大眾對科學研究的看法。最後將關注的場域由科學社群拓展到一般社群，解釋假資訊如何在普羅大眾之間散播。</p>
<p><strong>極化與從眾</strong></p>
<p>科學社群中可能出現的現象之一是立場的極化 (polarization) 。意見相左的兩個群體會因為各種原因而逐漸加深歧見，最後分別佔據光譜的兩個極端。假使有一名科學家企圖判定對立的兩個科學理論 A 和 B 孰真孰假，除了自己作實驗以外，另一個常見的做法是要求身邊的同儕提供研究的成果，藉以蒐集更多關於這兩個理論的資訊。如果他的同儕們恰好都是 A 理論的支持者，他們會傾向提供較為支持 A 理論的證據，進而大大地提高這位科學家接受 A 理論的機會。如果他因此斷定 A 理論是真的，進而認為所有接受 B 理論的人都在研究能力上出了問題，拒絕和他們交換資訊，就會出現意見極化的現象。接受不同科學理論的人互相將對方當作三流的科學家，形成了兩個不互相交流的封閉群體。兩個群體之中的科學家都無法接觸到另一邊的資訊，從而無法基於完整而全面的證據評價兩個理論的優劣。</p>
<p>一個與極化相似的現象是從眾 (conformity) 。科學家在研究特定議題的時候，時常會接觸到旁人的想法，並以此作為證據，推論出與這些人相同的結果。作者們用了一個簡單的案例來說明這個現象：假使有五十個人在考慮購入日產或通用汽車的股票，其中每一個人都各自有些不能與他人分享的小道消息。兩個人手上的消息顯示通用汽車的股票會表現得比較好；其他四十八人手上的消息恰好相反，支持購買日產的股票。假使頭兩個人買了通用汽車的股票，並且讓剩下的人看到自己做出了這樣的選擇，第三個人在做決定的時候可能會想：既然前面兩個人都買了通用，那我手頭上有的資訊或許是錯誤的。秉持這樣的想法，這個人也會傾向於買進通用汽車的股票。接下來的每一個人可能都會按照相同的思路，買進通用的股票。這樣的思路將會導致一個奇怪的結果：絕大多數人擁有的資訊都支持購買日產的股票，最後卻都做出了和自己資訊不相符的決定。和極化一樣，從眾的傾向也容易讓科學家形成一個意見單一的群體，而忽略了支持不同理論的證據。</p>
<p>這兩個現象恰好是對稱的：如果我們將他人的不同意見棄若敝屣，就會產生意見極化的風險；如果我們過於重視與自己立場相近的意見，就可能犯下從眾的缺失。它們導致相同的結果，使得科學家們無法平衡地評估各方的資訊。對熟悉心理學的讀者來說，這兩個現象大概是已經聽過千百遍的陳腔濫調。極化和從眾分別是確認偏誤 (confirmation bias) 和從眾偏誤 (conformity bias) 的結果，這兩種認知偏誤多年來已經被深入地討論和研究，為什麼哲學家還要大費周章地解釋這樣的老生常談？這個問題恰好揭示了本書的一個重點：就算每一個個體都高度理性，還是有可能散播錯誤的資訊。</p>
<p>作者們以經濟學中的 Bala-Goyal 模型模擬了科學社群內的資訊傳遞機制，這個模型只包含幾個點，以及將某些點相連的線段。每一個點代表一個科學家，兩點如果有線段連結，代表這兩個科學家會交換各自的研究成果。每一個點上有特定的數值，代表他們相信特定理論的程度。在每一個階段，科學家們參照他們從身邊同儕獲取的資訊，以貝葉斯定理 (Bayes' theorem) 修正自己對該理論的看法。從這樣一個高度抽象、不涉及任何認知偏誤的模型中，作者們仍然能夠推導出極化和從眾這兩個現象。這告訴我們：就算科學家在蒐集資訊的過程中保持著全然理性、不受偏誤左右的態度，只要他和同儕相互交換意見，並且依照所得到的證據修正對他人的看法，上述的兩個現象就很可能會出現。在這種理想的資訊交換過程中尚且如此，現實社會中的意見極化只可能會更加嚴重。</p>
<p><strong>「福音」如何廣傳？</strong></p>
<p>在大部分的情況中，科學家們都能夠藉由長期的研究得到正確的成果。就算有極化和從眾這兩個現象，頂多也只會減緩科學家找到正確理論的進度。一個更加嚴重的問題是對研究結果的蓄意扭曲：科學研究的結果時常受到外在因素的影響，因而無法被確實地傳達給社會大眾。</p>
<p>我們可以假想一個情境：科學家們提出了有力的證據，說明攝取糖分會增加骨質疏鬆的風險。倘若你是握有大量資金的製糖業鉅子，能夠如何挽救整個產業？除了買通科學家發布假的研究成果，說明糖分和骨質疏鬆並沒有關聯，你也可以贊助其他與骨質疏鬆相關的研究，藉以轉移大眾的注意力。很多時候，僅僅是製造出相關的的爭議，就可以有效地讓人們重拾對糖分的信心。</p>
<p>作者們在第三章中不將重點放在這些常見的手法，而著重在帶有特定意圖的宣傳 (propaganda) 之上。假使企業家指派一個宣傳者去接觸政策制定者 (policy maker) ，這個宣傳者能不能夠有效地影響公共決策？作者們將這兩種角色加入他們所使用的 Bala-Goyal 模型中，並且假設宣傳者選擇性地呈現科學研究的成果：蓄意地隱藏對自己不利的研究，只發放對自己有利或模棱兩可的證據。藉由這樣的模擬，作者們推演出了一個出人意表的結果：就算科學家們發現了正確的資訊，在科學社群中建立了明確的共識，同時和政策制定者之間也有直接的聯繫溝通，宣傳者仍然能夠藉由刻意揀選特定研究，有效地防止政策制定者們相信正確的資訊，進而阻止政府制定有礙企業發展的政策。</p>
<p>宣傳者能夠操弄公眾意見的前提是要有許多模稜兩可、沒有確切結論的研究。如果所有的相關研究都有非常明確的結果，那宣傳者就沒有任何操作的空間。作者們在此也介紹了使這類研究出現的幾個可能原因，其中最值得注意的是企業資金挹注方式能夠造成的影響。</p>
<p>要釐清這一點，我們可以先設想一個問題：假使你一個是製糖業者，希望科學家能在不造假的前提之下產出對你有利的實驗證據，你應該將手上的資金投資在一個大型的研究計畫，還是分散投資給十個不同的小型計畫？正確的答案是後者。假設每一百個糖分攝取過量的人中，有七成會出現骨質疏鬆的問題，大型的研究計畫可以容納大量的案例，使科學家正確地找出糖分攝取和骨質疏鬆之間的關聯；但在小型的研究計畫中，可能會有資料量不足，而無法得出顯著結果的情況。換句話說，藉由分散資金，企業家能夠防止大數法則 (law of large numbers) 發揮作用，而製造出不正確的研究成果。藉著大肆宣揚這類研究成果，宣傳者能夠有效地誤導大眾。我們能夠因此結論：讓更多的科學家投入同一個研究有可能適得其反，無法得出更準確的結果，如此一來，企業家便可以不必造假，而仍然達到掩蓋事實、保護自己產業的目的。</p>
<p><strong>社會的網絡</strong></p>
<p>這些發生在科學社群裡的問題，在普羅大眾的資訊傳遞過程中也很可能會出現。作者們在第四章中將討論延伸到了一般社群中的資訊交換。在此，他們聚焦於一個重要的問題：從事新聞報導的人有沒有可能在全無惡意的情況下，散播虛假的資訊？答案是肯定的，有兩個原因使得新聞從業者可能會在無意中助長假新聞的傳播。第一點是獵奇的心態。與平淡無奇的消息相比，記者通常更樂意報導罕見的故事以討好讀者。如同上個世紀《紐約太陽報》主編 John Bogart 所說的：「狗咬人不是新聞，人咬狗才是。」如果記者一直秉持這樣的準則，那麼，假資訊傳播的機率便會提高。何以如此？一則新聞之所以令人感到驚奇，正是因為它成真的可能性很低。真確的資訊時常是平凡無奇的，大部分正確的資訊相對缺乏報導的價值。如果記者總是挑選這些成真機率不高的資訊來報導，自然會散播比較多的假新聞。</p>
<p>另一個可能助長假資訊散播的做法是刻意地平衡報導。乍聽之下，平衡報導是一個很好的策略。作為中立的資訊傳遞者，記者理應公平地檢視所有的爭議；具體地說，記者在報導特定議題的時候，應該要均衡地呈現正反兩面的立場。每報導一則支持某議題的理由，也就該相應地報導一個反對的立場。然而，對於大部分的議題來說，這都會助長假新聞的傳播。以氣候變遷的爭議為例：假使有十個大規模的科學研究指出地球溫度確實因為人類活動而逐年上升，只有一個研究指出人類對氣溫沒有顯著的影響。堅持平衡報導的記者會為了公平呈現相關研究，選擇正反面的資訊各報導一則。這樣的做法會使得錯誤資訊和正確資訊在新聞中的佔比相同，而傳達給大眾兩方勢均力敵的錯誤印象。同樣地，作者也藉由 Bala-Goyal 模型模擬了這兩個情況，證明了在記者不具任何特定意圖的情況下，假新聞依然很可能會四處流竄。</p>
<p>在全書的末尾，作者對現行的民主體制提出一些反思：如果假新聞如此容易傳播，我們是不是應該重新思考合宜的政治體制？現行的體制或許已經無法保障民主原初的目標。因此，他們倡議科學哲學家 Philip Kitcher 所提出的「良序科學 (well-ordered science)」：公共決策應該要由有能力正確理解科學研究、衡量各方價值、並熟稔相關倫理議題的代議士進行審議。當然，這樣的想法明顯過於理想而不切實際。討論 Kitcher 藍圖的實際意義在於讓我們看到現今社會的弊病，而開始想辦法修正體制，盡可能解決這樣的問題。</p>
<p><em>The Misinformation Age</em> 在抽象思辨和具體反思的兩個面向上都提供了非常完整的討論。一方面，作者藉由許多具體發生過的案例來說明資訊傳遞過程中會出現的諸般現象，引導讀者們思考現象的成因；另一方面，作者們用抽象而簡明的模型成功地模擬出這些現象，並清楚地解釋模型如何運作，讓人能夠扼要地掌握訊息傳遞的模式。作為一本介紹性書籍，本書可以說是非常成功。就算是對數學模型不感興趣的讀者，也能夠跟著作者清晰的理路，明確地掌握每個章節的要旨。</p>
<p><strong>在此書以外：網絡理論的具體應用</strong></p>
<p>近期香港的反修例運動有一個特別的現象：去中心化。兩個多月的運動中，沒有一個負責統籌行動的核心，只有每一個個體（並不限於個人，也可能是不同規模的組織）自發性的行動。這樣的做法有許多好處，除了能夠保障沒有任何組織或個人能夠被咎責或招安，還能具體地展示民眾的普遍意志，不被特定團體的意見綁架。然而，在資訊傳遞上，這樣的做法會有較高昂的成本。依照現行的情況，每一個個體都得從網路論壇或新聞媒體上蒐集資訊，並頻繁地進行事實查核 (fact check) 。筆者有一個旅英的香港朋友，每個週末都在通訊軟體上協助傳遞資訊。他參照所有網路媒體畫面，將每個地方的現況轉告給參加示威的朋友，工作內容就像是蝙蝠俠系列電影中的阿福。由於講求速度，他也時常無意地轉傳了未經查核的資訊，因而對朋友做出錯誤的指引。</p>
<p>在網絡理論 (network theory) 裡有許多關於最佳 (optimal) 結構的證明，其中有一個十分值得參考：在資訊可能出錯的情況下，單一核心的資訊傳遞模式可以讓溝通的成本最小化。運動可以放棄決策核心，但如果有一個資訊核心，有沒有可能使運動本身進行得更加順利？根據筆者觀察，目前大部分的資訊來自於連登討論區和 Facebook 、 Twitch 等平台上各家新聞台的直播。在大部分情況下，這些資訊來源都能運作良好，但在某些緊急的狀況中，現行的作法仍然容易有資訊誤傳的問題。如果運動者群體能建立單一的資訊核心，一方面，如果掌握重要資訊的運動者想將手中的資訊分享出去，這樣的核心能作為一個彙整的平台，在時效允許的情況下，這個核心也能對接收到的資訊進行事實查核；另一方面，這個資訊核心可以客觀而中立地呈現各地的示威相關資訊，運動者或許能更有效地掌握情報，從而能夠有效地做出進退的決定。當然，和建立良序科學一樣，一個運作完美的資訊核心是難以企及的，但運動者社群或許仍然可以思考如何能夠讓相互傳遞的資訊更加精確，從而將因為資訊傳遞落差而要負擔的額外損害減到最低。</p>

  </section>
</article>
    
    
  

    
  
<footer class="l-container_footer">
  <nav class="pagination">
    <a href="/philosophy/%E5%A5%B3%E5%93%B2%E5%AD%B8%E5%AE%B6%E7%9A%84%E5%85%B7%E9%AB%94%E9%9D%A2%E8%B2%8C-%E4%BA%94%E6%9C%AC%E5%A5%BD%E6%9B%B8/" class="pagination-new" role="button"><span class="pagination-title">Next Post</span><br><span>女哲學家的具體面貌：五本好書</span></a>
    <a href="/philosophy/%E6%B2%89%E6%80%9D%E8%80%85%E6%88%BF%E9%96%93%E8%A3%A1%E7%9A%84%E5%A4%A7%E8%B1%A1-%E5%BE%9E%E5%BF%83%E6%99%BA%E5%93%B2%E5%AD%B8%E7%9C%8B%E5%8F%97%E8%8B%A6%E7%B6%93%E9%A9%97/" class="pagination-old" role="button"><span class="pagination-title">Previous Post</span><br><span>沉思者房間裡的大象：從心智哲學看受苦經驗</span></a>
  </nav>
</footer>

  </main>
  
  <footer id="site-footer">
  <p> | Powered by <a href="https://gohugo.io/">Hugo</a> and <a href="https://github.com/pacollins/calligraphy">Calligraphy</a></p>
</footer>
<script type="text/javascript" src="/js/bundle.min.4d7a56d861db7bbd6cadc54ede14158fddb7b9c2880a59b98e8382318dfbe688.js" crossorigin="anonymous" integrity="sha256-TXpW2GHbe71srcVO3hQVj923ucKIClm5joOCMY375og="></script>

  

</body>

</html>